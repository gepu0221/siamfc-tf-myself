{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os \n",
    "import numpy as np\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from tensorflow.python.framework import graph_util  \n",
    "from tensorflow.python.platform import gfile  \n",
    "#myself\n",
    "import src.make_siameseFC as siam\n",
    "from src.train_siam_net import train_siam_net\n",
    "from src.region_to_bbox import region_to_bbox\n",
    "from src.parse_arguments import parse_arguments\n",
    "\n",
    "_conv_w_sz=np.array([11,5,3,3,3]) #the map size of filter(weight of conv net)\n",
    "_conv_w_in_c=np.array([3,96,256,384,384])# the input channle number of filter\n",
    "_conv_w_out=np.array([96,256,384,384,256])# the output number of feature map(the number of filter kernel)\n",
    "\n",
    "def main():\n",
    "    #avoid printing TF debugging information(only show error log)\n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL']='3'\n",
    "    hp,evaluation,run,env,design=parse_arguments()\n",
    "    #build TF graph in siamese once for all\n",
    "    #siam.init_create_net()\n",
    "    filename,siam_net_z,loss,train_op=siam.make_siameseFC(env,design,hp)\n",
    "    \n",
    "    #iterate through all videos of evaluation.dataset\n",
    "    if evaluation.video == 'all':\n",
    "        #the path of folder of all videos\n",
    "        train_data_folder=os.path.join(env.root_train_dataset,evaluation.dataset)\n",
    "        videos_list=[v for v in os.listdir(train_data_folder)]\n",
    "        videos_list.sort()\n",
    "        num_v=len(videos_list)\n",
    "        for i in range(num_v):\n",
    "            gt,frame_name_list,frame_sz,n_frames=_init_train_video(env,evaluation,videos_list[i])\n",
    "            start_frame=evaluation.start_frame\n",
    "            #not sure\n",
    "            #gt_=gt[start_frame:,:]\n",
    "            gt_=gt[start_frame:]\n",
    "            frame_name_list_=frame_name_list[start_frame:]\n",
    "            num_frames=np.size(frame_name_list_)\n",
    "            \n",
    "            for j in range(num_frames-1):\n",
    "                pos_x,pos_y,target_w,target_h=region_to_bbox(gt_[j])\n",
    "                #train_siam_net(design,hp,frame_name_list,z_index,pos_x,pos_y,target_w,target_h,filename,siam_net_z,loss)\n",
    "                train_siam_net(design,hp,frame_name_list,j,pos_x,pos_y,target_w,target_h,filename,siam_net_z,loss,train_op)\n",
    "        \n",
    "    else:\n",
    "        gt,frame_name_list,_,_ = _init_train_video(env,evaluation,evaluation.video)\n",
    "        start_frame=evaluation.start_frame\n",
    "        gt_=gt[start_frame:]\n",
    "        frame_name_list_=frame_name_list[start_frame:]\n",
    "        num_frames=np.size(frame_name_list_)\n",
    "       \n",
    "        train_siam_net(design,hp,frame_name_list,num_frames,gt,filename,siam_net_z,loss,train_op)\n",
    "        '''for i in range(num_frames-1):\n",
    "            pos_x,pos_y,target_w,target_h=region_to_bbox(gt[evaluation.start_frame])\n",
    "            train_siam_net(design,hp,frame_name_list,i,pos_x,pos_y,target_w,target_h,filename,siam_net_z,loss,train_op)'''\n",
    "            \n",
    "    #write_file_param(design,env,evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _init_train_video(env,evaluation,video):\n",
    "     #-------------------------------------------------------------------------\n",
    "    #function//init info of a train video sequence\n",
    "    #-------------------------------------------------------------------------\n",
    "    #the path of train_data folder\n",
    "    train_data_folder=os.path.join(env.root_train_dataset,evaluation.dataset,video)\n",
    "    #os.listdir():show the file list of the folder\n",
    "    frame_name_list=[f for f in os.listdir(train_data_folder) if f.endswith(\".\"+env.image_type)]\n",
    "    frame_name_list=[os.path.join(train_data_folder,'')+s for s in frame_name_list]\n",
    "    frame_name_list.sort()\n",
    "    \n",
    "    #get the info of first frame\n",
    "    with Image.open(frame_name_list[0]) as img:\n",
    "        frame_sz=np.asarray(img.size)\n",
    "        ##????????????????????????????????????????????\n",
    "        frame_sz[1],frame_sz[0]=frame_sz[0],frame_sz[1]\n",
    "        \n",
    "        #read the initialization from ground truth(init the template_z)\n",
    "    gt_file=os.path.join(train_data_folder,evaluation.gt_name)\n",
    "    gt=np.genfromtxt(gt_file,delimiter=evaluation.gt_delimiter)\n",
    "    num_frame=len(frame_name_list)\n",
    "    assert num_frame == len(gt),'number of frame and number of gt should be the same'\n",
    "    \n",
    "    return gt,frame_name_list,frame_sz,num_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def write_file_param(design,env,evaluation):\\n    _layers_num=design.layers_num\\n    \\n    #get the time stamp now\\n    time_s=time.strftime(\\'%Y-%m-%d-%H:%M:%S\\',time.localtime(time.time()))\\n    re_filename=str(time_s)+evaluation.train_re_param_file\\n    re_file_path=os.path.join(env.root_train_result_param,re_filename)\\n    for i in range(_layers_num):\\n        scope_name=\\'conv\\'+str(i+1)\\n        with tf.variable_scope(scope_name,reuse=True):\\n            W_=tf.get_variable(\"W\",shape=[_conv_w_sz[i],_conv_w_sz[i],_conv_w_in_c[i],_conv_w_out[i]])\\n            b_=tf.get_variable(\"b\",shape=[_conv_w_out[i]])\\n            w_name=\\'W\\'+str(i)\\n            b_name=\\'b\\'+str(i)\\n            W_=tf.get_variable(w_name,shape=[_conv_w_sz[i],_conv_w_sz[i],_conv_w_in_c[i],_conv_w_out[i]],tf.constant_initalizer(W_))\\n            b_=tf.get_variable(b_name,shape=[_conv_w_out[i]],tf.constant_initalizer(b_))\\n    with tf.Session() as sess:\\n        sess.run(tf.global_variables_initializer())\\n        for i in range(_layers_num):\\n            w_name=\\'W\\'+str(i)\\n            b_name=\\'b\\'+str(i)\\n            graph_w=graph_util.convert_variables_to_constants(sess,sess.graph_def,[w_name])\\n            tf.train.wirte_graph(graph_w,\\'.\\',re_file_path,as_text=False)\\n            graph_b=graph_util.convert_variables_to_constants(sess,sess.graph_def,[b_name])\\n            tf.train.write_graph(graph_b,\\'.\\',re_file_path,as_text=False)'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def write_file_param(design,env,evaluation):\n",
    "    _layers_num=design.layers_num\n",
    "    \n",
    "    #get the time stamp now\n",
    "    time_s=time.strftime('%Y-%m-%d-%H:%M:%S',time.localtime(time.time()))\n",
    "    re_filename=str(time_s)+evaluation.train_re_param_file\n",
    "    re_file_path=os.path.join(env.root_train_result_param,re_filename)\n",
    "    for i in range(_layers_num):\n",
    "        scope_name='conv'+str(i+1)\n",
    "        with tf.variable_scope(scope_name,reuse=True):\n",
    "            W_=tf.get_variable(\"W\",shape=[_conv_w_sz[i],_conv_w_sz[i],_conv_w_in_c[i],_conv_w_out[i]])\n",
    "            b_=tf.get_variable(\"b\",shape=[_conv_w_out[i]])\n",
    "            w_name='W'+str(i)\n",
    "            b_name='b'+str(i)\n",
    "            W_=tf.get_variable(w_name,shape=[_conv_w_sz[i],_conv_w_sz[i],_conv_w_in_c[i],_conv_w_out[i]],tf.constant_initalizer(W_))\n",
    "            b_=tf.get_variable(b_name,shape=[_conv_w_out[i]],tf.constant_initalizer(b_))\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for i in range(_layers_num):\n",
    "            w_name='W'+str(i)\n",
    "            b_name='b'+str(i)\n",
    "            graph_w=graph_util.convert_variables_to_constants(sess,sess.graph_def,[w_name])\n",
    "            tf.train.wirte_graph(graph_w,'.',re_file_path,as_text=False)\n",
    "            graph_b=graph_util.convert_variables_to_constants(sess,sess.graph_def,[b_name])\n",
    "            tf.train.write_graph(graph_b,'.',re_file_path,as_text=False)'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer conv1\n",
      "Tensor(\"conv1/Relu:0\", shape=(1, 123, 123, 96), dtype=float32)\n",
      "Tensor(\"conv1/Relu_1:0\", shape=(1, 59, 59, 96), dtype=float32)\n",
      "_pool_stride\n",
      "Tensor(\"conv1/pool1:0\", shape=(1, 61, 61, 96), dtype=float32)\n",
      "Tensor(\"conv1/pool1_1:0\", shape=(1, 29, 29, 96), dtype=float32)\n",
      "Layer conv2\n",
      "Tensor(\"conv2/Relu:0\", shape=(1, 57, 57, 256), dtype=float32)\n",
      "Tensor(\"conv2/Relu_1:0\", shape=(1, 25, 25, 256), dtype=float32)\n",
      "_pool_stride\n",
      "Tensor(\"conv2/pool2:0\", shape=(1, 28, 28, 256), dtype=float32)\n",
      "Tensor(\"conv2/pool2_1:0\", shape=(1, 12, 12, 256), dtype=float32)\n",
      "Layer conv3\n",
      "Tensor(\"conv3/Relu:0\", shape=(1, 26, 26, 384), dtype=float32)\n",
      "Tensor(\"conv3/Relu_1:0\", shape=(1, 10, 10, 384), dtype=float32)\n",
      "Tensor(\"conv3/Relu:0\", shape=(1, 26, 26, 384), dtype=float32)\n",
      "Tensor(\"conv3/Relu_1:0\", shape=(1, 10, 10, 384), dtype=float32)\n",
      "Layer conv4\n",
      "Tensor(\"conv4/Relu:0\", shape=(1, 24, 24, 384), dtype=float32)\n",
      "Tensor(\"conv4/Relu_1:0\", shape=(1, 8, 8, 384), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(1, 24, 24, 384), dtype=float32)\n",
      "Tensor(\"conv4/Relu_1:0\", shape=(1, 8, 8, 384), dtype=float32)\n",
      "Layer conv5\n",
      "Tensor(\"conv5/add:0\", shape=(1, 22, 22, 256), dtype=float32)\n",
      "Tensor(\"conv5/add_1:0\", shape=(1, 6, 6, 256), dtype=float32)\n",
      "match_template\n",
      "begin calculate the loss\n",
      "loss end1\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n",
      "begin\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py:2918: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    sys.exit(main())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
