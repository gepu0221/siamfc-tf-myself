{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os \n",
    "import numpy as np\n",
    "import time\n",
    "from PIL import Image\n",
    "import src.make_siameseFC as siam\n",
    "from src.train_siam_net import train_siam_net\n",
    "from src.region_to_bbox import region_to_bbox\n",
    "from src.parse_arguments import parse_arguments\n",
    "\n",
    "def main():\n",
    "    #avoid printing TF debugging information(only show error log)\n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL']='3'\n",
    "    hp,evaluation,run,env,design=parse_arguments()\n",
    "    #build TF graph in siamese once for all\n",
    "    siam.init_create_net()\n",
    "    filename,siam_net_z,loss,train_op=siam.make_siameseFC(env,design,hp)\n",
    "    \n",
    "    #iterate through all videos of evaluation.dataset\n",
    "    if evaluation.video == 'all':\n",
    "        #the path of folder of all videos\n",
    "        train_data_folder=os.path.join(env.root_train_dataset,evaluation.dataset)\n",
    "        videos_list=[v for v in os.listdir(train_data_folder)]\n",
    "        videos_list.sort()\n",
    "        num_v=len(videos_list)\n",
    "        for i in range(num_v):\n",
    "            gt,frame_name_list,frame_sz,n_frames=_init_train_video(env,evaluation,videos_list[i])\n",
    "            start_frame=evaluation.start_frame\n",
    "            #not sure\n",
    "            #gt_=gt[start_frame:,:]\n",
    "            gt_=gt[start_frame:]\n",
    "            frame_name_list_=frame_name_list[start_frame:]\n",
    "            num_frames=np.size(frame_name_list_)\n",
    "            \n",
    "            for j in range(num_frames-1):\n",
    "                pos_x,pos_y,target_w,target_h=region_to_bbox(gt_[j])\n",
    "                #train_siam_net(design,hp,frame_name_list,z_index,pos_x,pos_y,target_w,target_h,filename,siam_net_z,loss)\n",
    "                train_siam_net(design,hp,frame_name_list,j,pos_x,pos_y,target_w,target_h,filename,siam_net_z,loss,train_op)\n",
    "        \n",
    "    else:\n",
    "        gt,frame_name_list,_,_ = _init_train_video(env,evaluation,evaluation.video)\n",
    "        start_frame=evaluation.start_frame\n",
    "        gt_=gt[start_frame:]\n",
    "        frame_name_list_=frame_name_list[start_frame:]\n",
    "        num_frames=np.size(frame_name_list_)\n",
    "        for i in range(num_frames-1):\n",
    "            pos_x,pos_y,target_w,target_h=region_to_bbox(gt[evaluation.start_frame])\n",
    "            train_siam_net(design,hp,frame_name_list,i,pos_x,pos_y,target_w,target_h,filename,siam_net_z,loss,train_op)\n",
    "            \n",
    "    write_file_param(design,env,evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _init_train_video(env,evaluation,video):\n",
    "     #-------------------------------------------------------------------------\n",
    "    #function//init info of a train video sequence\n",
    "    #-------------------------------------------------------------------------\n",
    "    #the path of train_data folder\n",
    "    train_data_folder=os.path.join(env.root_train_dataset,evaluation.dataset,video)\n",
    "    #os.listdir():show the file list of the folder\n",
    "    frame_name_list=[f for f in os.listdir(train_data_folder) if f.endswith(\".\"+env.image_type)]\n",
    "    frame_name_list=[os.path.join(train_data_folder,'')+s for s in frame_name_list]\n",
    "    frame_name_list.sort()\n",
    "    \n",
    "    #get the info of first frame\n",
    "    with Image.open(frame_name_list[0]) as img:\n",
    "        frame_sz=np.asarray(img.size)\n",
    "        ##????????????????????????????????????????????\n",
    "        frame_sz[1],frame_sz[0]=frame_sz[0],frame_sz[1]\n",
    "        \n",
    "        #read the initialization from ground truth(init the template_z)\n",
    "    gt_file=os.path.join(train_data_folder,evaluation.gt_name)\n",
    "    gt=np.genfromtxt(gt_file,delimiter=evaluation.gt_delimiter)\n",
    "    num_frame=len(frame_name_list)\n",
    "    assert num_frame == len(gt),'number of frame and number of gt should be the same'\n",
    "    \n",
    "    return gt,frame_name_list,frame_sz,num_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_file_param(design,env,evaluation):\n",
    "    _layers_num=design.layers_num\n",
    "    \n",
    "    #get the time stamp now\n",
    "    time_s=time.strftime('%Y-%m-%d-%H:%M:%S',time.localtime(time.time()))\n",
    "    re_filename=str(time_s)+evaluation.train_re_param_file\n",
    "    re_file_path=os.path.join(env.train_result_param,re_filename)\n",
    "    for i in range(_layers_num):\n",
    "        scope_name='conv'+str(i+1)\n",
    "        with tf.variable_scope(scope_name,ruese=True):\n",
    "            W_=tf.get_variable(\"W\",shape=[])\n",
    "            b_=tf.get_variable(\"b\",shape=[])\n",
    "            w_name='W'+str[i]\n",
    "            b_name='b'+str[i]\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for i in range(_layers_num):\n",
    "            w_name='W'+str[i]\n",
    "            b_name='b'+str[i]\n",
    "            graph_w=convert_variables_to_constants(sess,sess.graph_def,[w_name])\n",
    "            tf.train.wirte_graph(graph_w,'.',re_file_path,as_text=False)\n",
    "            graph_b=convert_variables_to_constants(sess,sess.graph_def,[b_name])\n",
    "            tf.train.write_graph(graph_b,'.',re_file_path,as_text=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder_3:0\", dtype=float64)\n",
      "Layer 1\n",
      "Tensor(\"ExpandDims_2:0\", shape=(1, 127, 127, ?), dtype=float32)\n",
      "Tensor(\"ExpandDims_5:0\", shape=(1, 255, 255, ?), dtype=float32)\n",
      "Tensor(\"conv1_2/Relu:0\", shape=(1, 59, 59, 96), dtype=float32)\n",
      "Tensor(\"conv1_1/Relu:0\", shape=(1, 123, 123, 96), dtype=float32)\n",
      "Layer 1 conv end\n",
      "_pool_stride\n",
      "Tensor(\"pool1_1:0\", shape=(1, 29, 29, 96), dtype=float32)\n",
      "Tensor(\"pool1:0\", shape=(1, 61, 61, 96), dtype=float32)\n",
      "Layer 1 end\n",
      "Layer 2\n",
      "Tensor(\"pool1_1:0\", shape=(1, 29, 29, 96), dtype=float32)\n",
      "Tensor(\"pool1:0\", shape=(1, 61, 61, 96), dtype=float32)\n",
      "Tensor(\"conv2_2/Relu:0\", shape=(1, 25, 25, 256), dtype=float32)\n",
      "Tensor(\"conv2_1/Relu:0\", shape=(1, 57, 57, 256), dtype=float32)\n",
      "Layer 2 conv end\n",
      "_pool_stride\n",
      "Tensor(\"pool2_1:0\", shape=(1, 12, 12, 256), dtype=float32)\n",
      "Tensor(\"pool2:0\", shape=(1, 28, 28, 256), dtype=float32)\n",
      "Layer 2 end\n",
      "Layer 3\n",
      "Tensor(\"pool2_1:0\", shape=(1, 12, 12, 256), dtype=float32)\n",
      "Tensor(\"pool2:0\", shape=(1, 28, 28, 256), dtype=float32)\n",
      "Tensor(\"conv3_2/Relu:0\", shape=(1, 10, 10, 384), dtype=float32)\n",
      "Tensor(\"conv3_1/Relu:0\", shape=(1, 26, 26, 384), dtype=float32)\n",
      "Layer 3 conv end\n",
      "Tensor(\"conv3_2/Relu:0\", shape=(1, 10, 10, 384), dtype=float32)\n",
      "Tensor(\"conv3_1/Relu:0\", shape=(1, 26, 26, 384), dtype=float32)\n",
      "Layer 3 end\n",
      "Layer 4\n",
      "Tensor(\"conv3_2/Relu:0\", shape=(1, 10, 10, 384), dtype=float32)\n",
      "Tensor(\"conv3_1/Relu:0\", shape=(1, 26, 26, 384), dtype=float32)\n",
      "Tensor(\"conv4_2/Relu:0\", shape=(1, 8, 8, 384), dtype=float32)\n",
      "Tensor(\"conv4_1/Relu:0\", shape=(1, 24, 24, 384), dtype=float32)\n",
      "Layer 4 conv end\n",
      "Tensor(\"conv4_2/Relu:0\", shape=(1, 8, 8, 384), dtype=float32)\n",
      "Tensor(\"conv4_1/Relu:0\", shape=(1, 24, 24, 384), dtype=float32)\n",
      "Layer 4 end\n",
      "Layer 5\n",
      "Tensor(\"conv4_2/Relu:0\", shape=(1, 8, 8, 384), dtype=float32)\n",
      "Tensor(\"conv4_1/Relu:0\", shape=(1, 24, 24, 384), dtype=float32)\n",
      "Tensor(\"conv5_2/add:0\", shape=(1, 6, 6, 256), dtype=float32)\n",
      "Tensor(\"conv5_1/add:0\", shape=(1, 22, 22, 256), dtype=float32)\n",
      "Layer 5 conv end\n",
      "Tensor(\"conv5_2/add:0\", shape=(1, 6, 6, 256), dtype=float32)\n",
      "Tensor(\"conv5_1/add:0\", shape=(1, 22, 22, 256), dtype=float32)\n",
      "Layer 5 end\n",
      "match_template\n",
      "begin calculate the loss\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No variables to optimize.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-988454cf1761>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-a8707ef3e9db>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m#build TF graph in siamese once for all\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0msiam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_create_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msiam_net_z\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msiam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_siameseFC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdesign\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m#iterate through all videos of evaluation.dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/gp/EyeSurgery/siamfc/siamfc-tf-myself/training/src/make_siameseFC.py\u001b[0m in \u001b[0;36mmake_siameseFC\u001b[0;34m(env, design, hp)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;31m#train --back propagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;31m#the train_op trains the variables that define with \"tf.Variable\" or \"tf.get_variable\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0mtrain_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss end1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/optimizer.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, loss, global_step, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, name, grad_loss)\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0maggregation_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation_method\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m         grad_loss=grad_loss)\n\u001b[0m\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0mvars_with_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/optimizer.py\u001b[0m in \u001b[0;36mcompute_gradients\u001b[0;34m(self, loss, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, grad_loss)\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0mprocessors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_get_processor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No variables to optimize.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m     \u001b[0mvar_refs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprocessors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     grads = gradients.gradients(\n",
      "\u001b[0;31mValueError\u001b[0m: No variables to optimize."
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    sys.exit(main())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
