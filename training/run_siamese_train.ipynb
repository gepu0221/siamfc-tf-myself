{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer conv1\n",
      "Tensor(\"conv1/Relu:0\", shape=(1, 123, 123, 96), dtype=float32)\n",
      "Tensor(\"conv1/Relu_1:0\", shape=(1, 59, 59, 96), dtype=float32)\n",
      "_pool_stride\n",
      "Tensor(\"conv1/pool1:0\", shape=(1, 61, 61, 96), dtype=float32)\n",
      "Tensor(\"conv1/pool1_1:0\", shape=(1, 29, 29, 96), dtype=float32)\n",
      "Layer conv2\n",
      "Tensor(\"conv2/Relu:0\", shape=(1, 57, 57, 256), dtype=float32)\n",
      "Tensor(\"conv2/Relu_1:0\", shape=(1, 25, 25, 256), dtype=float32)\n",
      "_pool_stride\n",
      "Tensor(\"conv2/pool2:0\", shape=(1, 28, 28, 256), dtype=float32)\n",
      "Tensor(\"conv2/pool2_1:0\", shape=(1, 12, 12, 256), dtype=float32)\n",
      "Layer conv3\n",
      "Tensor(\"conv3/Relu:0\", shape=(1, 26, 26, 384), dtype=float32)\n",
      "Tensor(\"conv3/Relu_1:0\", shape=(1, 10, 10, 384), dtype=float32)\n",
      "Tensor(\"conv3/Relu:0\", shape=(1, 26, 26, 384), dtype=float32)\n",
      "Tensor(\"conv3/Relu_1:0\", shape=(1, 10, 10, 384), dtype=float32)\n",
      "Layer conv4\n",
      "Tensor(\"conv4/Relu:0\", shape=(1, 24, 24, 384), dtype=float32)\n",
      "Tensor(\"conv4/Relu_1:0\", shape=(1, 8, 8, 384), dtype=float32)\n",
      "Tensor(\"conv4/Relu:0\", shape=(1, 24, 24, 384), dtype=float32)\n",
      "Tensor(\"conv4/Relu_1:0\", shape=(1, 8, 8, 384), dtype=float32)\n",
      "Layer conv5\n",
      "Tensor(\"conv5/add:0\", shape=(1, 22, 22, 256), dtype=float32)\n",
      "Tensor(\"conv5/add_1:0\", shape=(1, 6, 6, 256), dtype=float32)\n",
      "match_template\n",
      "begin calculate the loss\n",
      "loss end1\n",
      "train_data/EyeSurgery\n",
      "2\n",
      "train_data/EyeSurgery/01\n",
      "773\n",
      "773\n",
      "train_data/EyeSurgery/02\n",
      "773\n",
      "773\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py:2918: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os \n",
    "import numpy as np\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from tensorflow.python.framework import graph_util  \n",
    "from tensorflow.python.platform import gfile  \n",
    "#myself\n",
    "import src.make_siameseFC as siam\n",
    "from src.train_siam_net import train_siam_net\n",
    "from src.region_to_bbox import region_to_bbox\n",
    "from src.parse_arguments import parse_arguments\n",
    "\n",
    "_conv_w_sz=np.array([11,5,3,3,3]) #the map size of filter(weight of conv net)\n",
    "_conv_w_in_c=np.array([3,96,256,384,384])# the input channle number of filter\n",
    "_conv_w_out=np.array([96,256,384,384,256])# the output number of feature map(the number of filter kernel)\n",
    "_nums_layers=5\n",
    "\n",
    "def main():\n",
    "    #avoid printing TF debugging information(only show error log)\n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL']='3'\n",
    "    hp,evaluation,run,env,design=parse_arguments()\n",
    "    #build TF graph in siamese once for all\n",
    "    #siam.init_create_net()\n",
    "    filename,siam_net_z,loss,train_op=siam.make_siameseFC(env,design,hp)\n",
    "    #read mat file from net_path\n",
    "    params_names_list,params_values_list=_import_from_matconvent(net_path)\n",
    "    conv_W=[1,_num_layers]\n",
    "    for i in range(_nums_layers):\n",
    "        conv_W_name=_find_params('conv'+str(i+1)+'f',params_names_list)[0]\n",
    "        conv_b_name=_find_params('conv'+str(i+1)+'b',params_names_list)[0]\n",
    "        conv_W[i]=params_values_list[params_names_list.index(conv_W_name)]\n",
    "        conv_b[i]=params_values_list[params_names_list.index(conv_b_name)]\n",
    "    \n",
    "    #iterate through all videos of evaluation.dataset\n",
    "    if evaluation.video == 'all':\n",
    "        #the path of folder of all videos\n",
    "        train_data_folder=os.path.join(env.root_train_dataset,evaluation.dataset)\n",
    "        print(train_data_folder)\n",
    "        videos_list=[v for v in os.listdir(train_data_folder)]\n",
    "        videos_list.sort()\n",
    "        num_v=len(videos_list)\n",
    "        print(num_v)\n",
    "        for i in range(num_v):\n",
    "            gt,frame_name_list,_,_ = _init_train_video(env,evaluation,videos_list[i])\n",
    "            start_frame=evaluation.start_frame\n",
    "            gt_=gt[start_frame:]\n",
    "            frame_name_list_=frame_name_list[start_frame:]\n",
    "            num_frames=np.size(frame_name_list_)\n",
    "            train_siam_net(design,hp,frame_name_list,num_frames,gt,filename,conv_W,conv_b,siam_net_z,loss,train_op)\n",
    "        \n",
    "    else:\n",
    "        gt,frame_name_list,_,_ = _init_train_video(env,evaluation,evaluation.video)\n",
    "        start_frame=evaluation.start_frame\n",
    "        gt_=gt[start_frame:]\n",
    "        frame_name_list_=frame_name_list[start_frame:]\n",
    "        num_frames=np.size(frame_name_list_)\n",
    "       \n",
    "        train_siam_net(design,hp,frame_name_list,num_frames,gt,filename,conv_W,conv_b,siam_net_z,loss,train_op)\n",
    "            \n",
    "    #write_file_param(design,env,evaluation)\n",
    "    \n",
    "def _init_train_video(env,evaluation,video):\n",
    "     #-------------------------------------------------------------------------\n",
    "    #function//init info of a train video sequence\n",
    "    #-------------------------------------------------------------------------\n",
    "    #the path of train_data folder\n",
    "    train_data_folder=os.path.join(env.root_train_dataset,evaluation.dataset,video)\n",
    "    print(train_data_folder)\n",
    "    #os.listdir():show the file list of the folder\n",
    "    frame_name_list=[f for f in os.listdir(train_data_folder) if f.endswith(\".\"+env.image_type)]\n",
    "    frame_name_list=[os.path.join(train_data_folder,'')+s for s in frame_name_list]\n",
    "    frame_name_list.sort()\n",
    "    \n",
    "    #get the info of first frame\n",
    "    with Image.open(frame_name_list[0]) as img:\n",
    "        frame_sz=np.asarray(img.size)\n",
    "        ##????????????????????????????????????????????\n",
    "        frame_sz[1],frame_sz[0]=frame_sz[0],frame_sz[1]\n",
    "        \n",
    "        #read the initialization from ground truth(init the template_z)\n",
    "    gt_file=os.path.join(train_data_folder,evaluation.gt_name)\n",
    "    gt=np.genfromtxt(gt_file,delimiter=evaluation.gt_delimiter)\n",
    "    num_frame=len(frame_name_list)\n",
    "    print(num_frame)\n",
    "    print(len(gt))\n",
    "    assert num_frame == len(gt),'number of frame and number of gt should be the same'\n",
    "    \n",
    "    return gt,frame_name_list,frame_sz,num_frame\n",
    "\n",
    "if __name__=='__main__':\n",
    "    sys.exit(main())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
